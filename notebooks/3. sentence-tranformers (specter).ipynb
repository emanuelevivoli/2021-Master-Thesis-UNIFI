{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence-transformer\n",
    "\n",
    "This notebook uses the sentence-tranformer library. \n",
    "Here we are interested in using the pre-trained models from *sentence-transformer* for obtaining the embeddings of the title's and abstract's papers (if possible, also for the full-text). In this direction we are going to:\n",
    "\n",
    "- get the data in the first part of the notebook (*Dataset loader*), then\n",
    "- pre-training/fine-tuning our model on a big source of data in a *\"semi/supervised\"* manner (mostly unsupervised) and at the end\n",
    "- we will use our backbone (the model we trained untill now) on our downstream task using tranfer-learning approaches.  \n",
    "We will do some Ablation study on our model varying the architecture adding/changing/removing the pooling layer and investigating the attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Dataset loader\n",
    "In this section we'll build the classes to load the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# specter (search papers)\n",
    "\n",
    "In this following section we (with the support of the notebook from *sentence-transformer* library) uses the **specter model** for obtaining the embedding of the title's and abstract's papers. In this direction we have already built the dataloader in the section above, so what lefts is building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974 papers loaded\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#First, we load the papers dataset (with title and abstract information)\n",
    "DATA_PATH = '../data/sentence-tranformers/'\n",
    "dataset_file = DATA_PATH + 'emnlp2016-2018.json'\n",
    "\n",
    "if not os.path.exists(dataset_file):\n",
    "  util.http_get(\"https://sbert.net/datasets/emnlp2016-2018.json\", dataset_file)\n",
    "\n",
    "with open(dataset_file) as fIn:\n",
    "  papers = json.load(fIn)\n",
    "\n",
    "print(len(papers), \"papers loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f31d3051b84d4788318fe2662a5cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=612.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929314f04f70481a8e3dcc0301a1b09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=222296.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c4d09c44d24a68863a101202f29d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73aad5ada4764399b777dc827da9507d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=321.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#We then load the allenai-specter model with SentenceTransformers\n",
    "model = SentenceTransformer('allenai-specter')\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
    "\n",
    "#To encode the papers, we must combine the title and the abstracts to a single string\n",
    "paper_texts = [paper['title'] + tokenizer.sep_token + paper['abstract'] for paper in papers]\n",
    "\n",
    "#Compute embeddings for all papers\n",
    "corpus_embeddings = model.encode(paper_texts, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a function, given title & abstract, searches our corpus for relevant (similar) papers\n",
    "def search_papers(title, abstract):\n",
    "  query_embedding = model.encode(title+' '+abstract, convert_to_tensor=True)\n",
    "\n",
    "  search_hits = util.semantic_search(query_embedding, corpus_embeddings)\n",
    "  search_hits = search_hits[0]  #Get the hits for the first query\n",
    "\n",
    "  print(\"Paper:\", title)\n",
    "  print(\"Most similar papers:\")\n",
    "  for hit in search_hits:\n",
    "    related_paper = papers[hit['corpus_id']]\n",
    "    print(\"{:.2f}\\t{}\\t{} {}\".format(hit['score'], related_paper['title'], related_paper['venue'], related_paper['year']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Now we search for some papers that have been presented at EMNLP 2019 and 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: Specializing Word Embeddings (for Parsing) by Information Bottleneck\n",
      "Most similar papers:\n",
      "0.88\tAn Investigation of the Interactions Between Pre-Trained Word Embeddings, Character Models and POS Tags in Dependency Parsing\tEMNLP 2018\n",
      "0.88\tWord Embeddings for Code-Mixed Language Processing\tEMNLP 2018\n",
      "0.87\tWord Mover's Embedding: From Word2Vec to Document Embedding\tEMNLP 2018\n",
      "0.87\tGeneralizing Word Embeddings using Bag of Subwords\tEMNLP 2018\n",
      "0.87\tSegmentation-Free Word Embedding for Unsegmented Languages\tEMNLP 2017\n",
      "0.86\tGromov-Wasserstein Alignment of Word Embedding Spaces\tEMNLP 2018\n",
      "0.86\tNORMA: Neighborhood Sensitive Maps for Multilingual Word Embeddings\tEMNLP 2018\n",
      "0.86\tLAMB: A Good Shepherd of Morphologically Rich Languages\tEMNLP 2016\n",
      "0.85\tNeural Machine Translation with Source Dependency Representation\tEMNLP 2017\n",
      "0.85\tAddressing Troublesome Words in Neural Machine Translation\tEMNLP 2018\n"
     ]
    }
   ],
   "source": [
    "# This paper was the EMNLP 2019 Best Paper\n",
    "search_papers(title='Specializing Word Embeddings (for Parsing) by Information Bottleneck', \n",
    "              abstract='Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction. Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction. Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction. Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: Digital Voicing of Silent Speech\n",
      "Most similar papers:\n",
      "0.81\tSession-level Language Modeling for Conversational Speech\tEMNLP 2018\n",
      "0.79\tNeural Multitask Learning for Simile Recognition\tEMNLP 2018\n",
      "0.78\tSpeech segmentation with a neural encoder model of working memory\tEMNLP 2017\n",
      "0.76\tMSMO: Multimodal Summarization with Multimodal Output\tEMNLP 2018\n",
      "0.76\tEstimating Marginal Probabilities of n-grams for Recurrent Neural Language Models\tEMNLP 2018\n",
      "0.75\tLearning Unsupervised Word Translations Without Adversaries\tEMNLP 2018\n",
      "0.75\tA Co-Attention Neural Network Model for Emotion Cause Analysis with Emotional Context Awareness\tEMNLP 2018\n",
      "0.74\tMultimodal Language Analysis with Recurrent Multistage Fusion\tEMNLP 2018\n",
      "0.74\tLarge Margin Neural Language Model\tEMNLP 2018\n",
      "0.74\tICON: Interactive Conversational Memory Network for Multimodal Emotion Detection\tEMNLP 2018\n"
     ]
    }
   ],
   "source": [
    "# This paper was the EMNLP 2020 Best Paper\n",
    "search_papers(title='Digital Voicing of Silent Speech',\n",
    "              abstract='In this paper, we consider the task of digitally voicing silent speech, where silently mouthed words are converted to audible speech based on electromyography (EMG) sensor measurements that capture muscle impulses. While prior work has focused on training speech synthesis models from EMG collected during vocalized speech, we are the first to train from EMG collected during silently articulated speech. We introduce a method of training on silent EMG by transferring audio targets from vocalized to silent signals. Our method greatly improves intelligibility of audio generated from silent EMG compared to a baseline that only trains with vocalized data, decreasing transcription word error rate from 64% to 4% in one data condition and 88% to 68% in another. To spur further development on this task, we share our new dataset of silent and vocalized facial EMG measurements.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: If beam search is the answer, what was the question?\n",
      "Most similar papers:\n",
      "0.91\tA Stable and Effective Learning Strategy for Trainable Greedy Decoding\tEMNLP 2018\n",
      "0.90\tBreaking the Beam Search Curse: A Study of (Re-)Scoring Methods and Stopping Criteria for Neural Machine Translation\tEMNLP 2018\n",
      "0.89\tWhy Neural Translations are the Right Length\tEMNLP 2016\n",
      "0.88\tLearning Neural Templates for Text Generation\tEMNLP 2018\n",
      "0.86\tTowards Decoding as Continuous Optimisation in Neural Machine Translation\tEMNLP 2017\n",
      "0.86\tMulti-Reference Training with Pseudo-References for Neural Translation and Text Generation\tEMNLP 2018\n",
      "0.86\tA Tree-based Decoder for Neural Machine Translation\tEMNLP 2018\n",
      "0.86\tOnline Segment to Segment Neural Transduction\tEMNLP 2016\n",
      "0.86\tMemory-enhanced Decoder for Neural Machine Translation\tEMNLP 2016\n",
      "0.86\tTrainable Greedy Decoding for Neural Machine Translation\tEMNLP 2017\n"
     ]
    }
   ],
   "source": [
    "# This paper was a EMNLP 2020 Honourable Mention Papers\n",
    "search_papers(title='If beam search is the answer, what was the question?',\n",
    "              abstract='Quite surprisingly, exact maximum a posteriori (MAP) decoding of neural language generators frequently leads to low-quality results. Rather, most state-of-the-art results on language generation tasks are attained using beam search despite its overwhelmingly high search error rate. This implies that the MAP objective alone does not express the properties we desire in text, which merits the question: if beam search is the answer, what was the question? We frame beam search as the exact solution to a different decoding objective in order to gain insights into why high probability under a model alone may not indicate adequacy. We find that beam search enforces uniform information density in text, a property motivated by cognitive science. We suggest a set of decoding objectives that explicitly enforce this property and find that exact decoding with these objectives alleviates the problems encountered when decoding poorly calibrated language generation models. Additionally, we analyze the text produced using various decoding strategies and see that, in our neural machine translation experiments, the extent to which this property is adhered to strongly correlates with BLEU.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: Spot The Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems\n",
      "Most similar papers:\n",
      "0.86\tMulti-view Response Selection for Human-Computer Conversation\tEMNLP 2016\n",
      "0.84\tPatterns of Argumentation Strategies across Topics\tEMNLP 2017\n",
      "0.83\tNatural Language Does Not Emerge ‘Naturally’ in Multi-Agent Dialog\tEMNLP 2017\n",
      "0.83\tTowards Exploiting Background Knowledge for Building Conversation Systems\tEMNLP 2018\n",
      "0.82\tAirDialogue: An Environment for Goal-Oriented Dialogue Research\tEMNLP 2018\n",
      "0.82\tSpider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task\tEMNLP 2018\n",
      "0.82\tWikiConv: A Corpus of the Complete Conversational History of a Large Online Collaborative Community\tEMNLP 2018\n",
      "0.82\tThe Teams Corpus and Entrainment in Multi-Party Spoken Dialogues\tEMNLP 2016\n",
      "0.81\tDeal or No Deal? End-to-End Learning of Negotiation Dialogues\tEMNLP 2017\n",
      "0.80\tMultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling\tEMNLP 2018\n"
     ]
    }
   ],
   "source": [
    "# This paper was a EMNLP 2020 Honourable Mention Papers\n",
    "search_papers(title='Spot The Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems',\n",
    "              abstract='The lack of time efficient and reliable evalu-ation methods is hampering the development of conversational dialogue systems (chat bots). Evaluations that require humans to converse with chat bots are time and cost intensive, put high cognitive demands on the human judges, and tend to yield low quality results. In this work, we introduce Spot The Bot, a cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots. Human judges then only annotate for each entity in a conversation whether they think it is human or not (assuming there are humans participants in these conversations). These annotations then allow us to rank chat bots regarding their ability to mimic conversational behaviour of humans. Since we expect that all bots are eventually recognized as such, we incorporate a metric that measures which chat bot is able to uphold human-like be-havior the longest, i.e.Survival Analysis. This metric has the ability to correlate a bot’s performance to certain of its characteristics (e.g.fluency or sensibleness), yielding interpretable results. The comparably low cost of our frame-work allows for frequent evaluations of chatbots during their evaluation cycle. We empirically validate our claims by applying Spot The Bot to three domains, evaluating several state-of-the-art chat bots, and drawing comparisonsto related work. The framework is released asa ready-to-use tool.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMNLP 2020 paper on making Sentence-BERT multilingual\n",
    "search_papers(title='Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation',\n",
    "              abstract='We present an easy and efficient method to extend existing sentence embedding models to new languages. This allows to create multilingual versions from previously monolingual models. The training is based on the idea that a translated sentence should be mapped to the same location in the vector space as the original sentence. We use the original (monolingual) model to generate sentence embeddings for the source language and then train a new system on translated sentences to mimic the original model. Compared to other methods for training multilingual sentence embeddings, this approach has several advantages: It is easy to extend existing models with relatively few samples to new languages, it is easier to ensure desired properties for the vector space, and the hardware requirements for training is lower. We demonstrate the effectiveness of our approach for 50+ languages from various language families. Code to extend sentence embeddings models to more than 400 languages is publicly available.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
