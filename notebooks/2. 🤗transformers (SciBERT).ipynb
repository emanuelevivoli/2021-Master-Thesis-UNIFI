{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciBERT reimplementation \n",
    "We use allen-sciBERT weights for the huggingface library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers > transformers_installation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/vivoli/miniconda3/envs/arxiv-manipulation/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "from transformers import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'allenai/scibert_scivocab_uncased'\n",
    "# MODEL_PATH = 'allenai/scibert_scivocab_cased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModel.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also other models/vocabs that can be used (specifically for SciBERT, from the huggingface library):\n",
    "\n",
    "- scibert-scivocab-uncased (Recommended)\n",
    "- scibert-scivocab-cased\n",
    "- scibert-basevocab-uncased\n",
    "- scibert-basevocab-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We, now, load some data (Langulage Modeling tasks such as STS and Keyphrase) just to see how they can be mixed together."
   ]
  },
  {
   "source": [
    "tokenizer.vocab"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyphrase  s2orc-full-20200705v1  s2orc-sample-20200705v1  sentence-tranformers\r\n",
      "README.md  s2orc-mini\t\t  scibert\t\t   snli_1.0\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scispacy > scispacy_installation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "   \n",
    "    \n",
    "\n",
    "#Sentences we want sentence embeddings for\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "             'Sentences are passed as a list of string.',\n",
    "             'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModel.from_pretrained(MODEL_PATH)\n",
    "\n",
    "#Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "#Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3799,  0.6788, -0.1119,  ..., -0.2169, -0.9323, -0.0378],\n",
       "        [-0.0321,  0.2644,  0.1901,  ...,  0.1506, -0.1151,  0.1622],\n",
       "        [-0.8504, -0.1624, -0.6954,  ..., -0.1627, -0.2877, -0.5472]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python379jvsc74a57bd0d43c1c91074796e9cdbd2de8c16a4204853f397f18b12204d8a87a17f680418e",
   "display_name": "Python 3.7.9 64-bit ('arxiv-manipulation': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}