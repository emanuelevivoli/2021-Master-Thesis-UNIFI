{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4fd614",
   "metadata": {},
   "source": [
    "# Clustering and Visulization\n",
    "## using sentence_transformers\n",
    "---\n",
    "This is a simple application for sentence embeddings: clustering\n",
    "Sentences are mapped to sentence embeddings and then multiple clustering algorithms are applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b134d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "mag_field_dict: Dict = {\n",
    "    \"Medicine\"             : 0,\n",
    "    \"Biology\"              : 1,\n",
    "    \"Chemistry\"            : 2,\n",
    "    \"null\"                 : 3,  # n/a\n",
    "    \"Engineering\"          : 4,\n",
    "    \"Computer Science\"     : 5,\n",
    "    \"Physics\"              : 6,\n",
    "    \"Materials Science\"    : 7,\n",
    "    \"Mathematics\"          : 8,\n",
    "    \"Psychology\"           : 9,\n",
    "    \"Economics\"            : 10,\n",
    "    \"Political Science\"    : 11,\n",
    "    \"Business\"             : 12,\n",
    "    \"Geology\"              : 13,\n",
    "    \"Sociology\"            : 14,\n",
    "    \"Geography\"            : 15,\n",
    "    \"Environmental Science\": 16,\n",
    "    \"Art\"                  : 17,\n",
    "    \"History\"              : 18,\n",
    "    \"Philosophy\"           : 19\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4711319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a0a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r s2orc_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b82fb6",
   "metadata": {},
   "source": [
    "We count per field how many elements we have in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_mags = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec07891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680f23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e7e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8276b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f3a76f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e2bdfb86fa8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mfill_train_examples_per_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_class_limit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcurrent_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurrent_counter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mper_class_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_counter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collections' is not defined"
     ]
    }
   ],
   "source": [
    "def fill_train_examples_per_class(example, per_class_limit: int, counter: collections.Counter):\n",
    "    label = int(example['label'])\n",
    "    current_counter = counter.get(label, 0)\n",
    "    if current_counter < per_class_limit:\n",
    "        counter[label] = current_counter + 1\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d73c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract', 'mag_field_of_study', 'title']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3678f869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': Value(dtype='string', id=None),\n",
       " 'title': Value(dtype='string', id=None),\n",
       " 'mag_field_of_study': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cd884d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequence' object has no attribute 'names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d09d5d59b1bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms2orc_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mag_field_of_study'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequence' object has no attribute 'names'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc65ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivoli/miniconda3/envs/thesis/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b9494bf0dcb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2orc_chunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2orc_chunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mag_field_of_study'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms2orc_chunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mag_field_of_study'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2195\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \"\"\"\n\u001b[1;32m   1386\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1716\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ce337",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d58ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = s2orc_chunk['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "%time corpus_embeddings = embedder.encode(corpus, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa022a",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "---\n",
    "Here we cover the code for visualizing the clusters generated by kmeans, hierarchical and fast-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8679395",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d(red_algorithm, num_clusters, x, y, label):\n",
    "    # print\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_xlabel(f'{red_algorithm} 1', fontsize = 15)\n",
    "    ax.set_ylabel(f'{red_algorithm} 2', fontsize = 15)\n",
    "    ax.set_title(f'2 Component {red_algorithm}', fontsize = 20)\n",
    "\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    targets = [f'Cluster {i}' for i in range(num_clusters)] # + ['Centroids']\n",
    "    markers = list(Line2D.markers.keys())[:num_clusters] # + ['$c$']\n",
    "    \n",
    "    print(f\"targets: {targets}\")\n",
    "    print(f\"markers: {markers}\")\n",
    "    \n",
    "\n",
    "    for idx, (target, marker) in enumerate(zip(targets, markers)):\n",
    "        indicesToKeep = label == idx # finalDf['target'] == idx\n",
    "        ax.scatter(x[indicesToKeep], # finalDf.loc[indicesToKeep, f'{red_algorithm} 1'],\n",
    "                   y[indicesToKeep], # finalDf.loc[indicesToKeep, f'{red_algorithm} 2'],\n",
    "                   marker = marker,\n",
    "                   # c = color,\n",
    "                   s = 50)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "    plt.savefig(os.path.join(OUT_PATH, 'imgs', 'umap_hdbscan_umap.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(red_algorithm, num_clusters, x, y, z, label):\n",
    "    # print\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    # ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_xlabel(f'{red_algorithm} 1', fontsize = 15)\n",
    "    ax.set_ylabel(f'{red_algorithm} 2', fontsize = 15)\n",
    "    ax.set_zlabel(f'{red_algorithm} 3', fontsize = 15)\n",
    "    ax.set_title(f'3 Component {red_algorithm}', fontsize = 20)\n",
    "\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    targets = [f'Cluster {i}' for i in range(num_clusters)] #  + ['Centroids']\n",
    "    markers = list(Line2D.markers.keys())[:num_clusters] # + ['$c$']\n",
    "    \n",
    "    print(f\"targets: {targets}\")\n",
    "    print(f\"markers: {markers}\")\n",
    "\n",
    "    for idx, (target, marker) in enumerate(zip(targets, markers)):\n",
    "        indicesToKeep = label == idx # finalDf['target'] == idx\n",
    "        ax.scatter(x[indicesToKeep], # finalDf.loc[indicesToKeep, f'{red_algorithm} 1'],\n",
    "                   y[indicesToKeep], # finalDf.loc[indicesToKeep, f'{red_algorithm} 2'],\n",
    "                   z[indicesToKeep], # finalDf.loc[indicesToKeep, f'{red_algorithm} 3'],\n",
    "                   marker = marker,\n",
    "                   # c = color,\n",
    "                   s = 50)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "    plt.savefig(os.path.join(OUT_PATH, 'imgs', 'umap_hdbscan_umap.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803be744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "try:\n",
    "    from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "except:\n",
    "    print(\"For reasonable computation time, install Multicore-TSNE!\")\n",
    "    from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f01031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(red_algorithm, plot_dim, num_clusters, vectors, _labels):\n",
    "\n",
    "    # print(f\"***     Plot {plot_dim}D      ***\")\n",
    "    # perfect_half_spaces = ''*(10-len(red_algorithm))\n",
    "    # print(f\"* {perfect_half_spaces + red_algorithm + perfect_half_spaces} *\")\n",
    "    # print(f\"num_clusters: {num_clusters}\")\n",
    "    # print(f\"vectors (shape): {vectors.shape}\")\n",
    "    # print(f\"_labels (shape): {_labels.shape}\")\n",
    "    # print(\"*\"*25)\n",
    "        \n",
    "    _labels = _labels\n",
    "    _vectors = StandardScaler().fit_transform(vectors)\n",
    "    \n",
    "    if red_algorithm == 'pca':\n",
    "        plot_dim = 3\n",
    "        algorithm = PCA(n_components=plot_dim)\n",
    "    elif red_algorithm == 'tsne':\n",
    "        algorithm = TSNE(n_components=plot_dim)\n",
    "    elif red_algorithm == 'umap':\n",
    "        algorithm = UMAP(n_components=plot_dim)\n",
    "    else:\n",
    "        raise ValueError(f\"The PLOT algorithm {red_algorithm} is not supported, yet!\")\n",
    "    \n",
    "    red_vectors = algorithm.fit_transform(_vectors)\n",
    "\n",
    "    # dataframes from pandas\n",
    "    principalDf = pd.DataFrame(data = red_vectors, columns = [f'{red_algorithm} {num+1}' for num in range(plot_dim)])\n",
    "    labelDf =  pd.DataFrame(data = _labels, columns = ['target'])\n",
    "    finalDf = pd.concat([principalDf, labelDf], axis = 1)\n",
    "    \n",
    "    if red_algorithm == 'pca':\n",
    "        plot_2d(red_algorithm, num_clusters, finalDf[f'{red_algorithm} 1'], finalDf[f'{red_algorithm} 2'], finalDf['target'])\n",
    "        plot_3d(red_algorithm, num_clusters, finalDf[f'{red_algorithm} 1'], finalDf[f'{red_algorithm} 2'], finalDf[f'{red_algorithm} 3'], finalDf['target'])\n",
    "    else:\n",
    "        if plot_dim == 2:\n",
    "            plot_2d(red_algorithm, num_clusters, finalDf[f'{red_algorithm} 1'], finalDf[f'{red_algorithm} 2'], finalDf['target'])\n",
    "        elif plot_dim == 3:\n",
    "            plot_3d(red_algorithm, num_clusters, finalDf[f'{red_algorithm} 1'], finalDf[f'{red_algorithm} 2'], finalDf[f'{red_algorithm} 3'], finalDf['target'])\n",
    "        else:\n",
    "            raise ValueError(f\"plot_dim not supported {plot_dim} !!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecfee1f",
   "metadata": {},
   "source": [
    "# K-means\n",
    "---\n",
    "Use of k-mean clustering.\n",
    "Sentences are mapped to sentence embeddings and then k-mean clustering is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348702ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64251c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform kmean clustering\n",
    "num_clusters = 20\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "%time clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2orc_chunk['mag_field_of_study'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6988a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2fbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_mags = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_mags[cluster_id] += s2orc_chunk['mag_field_of_study'][sentence_id]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21af03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i)\n",
    "    print(cluster[:10])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = corpus_embeddings\n",
    "_labels = clustering_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654150d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algorithms = ['pca', 'tsne', 'umap'] \n",
    "dimentions = [ 2, 3 ]\n",
    "\n",
    "for red_algorithm in algorithms:\n",
    "    plot_algorithm(red_algorithm, plot_dim, num_clusters, vectors, _labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b12dc",
   "metadata": {},
   "source": [
    "# Hierarchical clustering\n",
    "---\n",
    "Use of Hierarchical clustering.\n",
    "Sentences are mapped to sentence embeddings and then agglomerative clustering with a threshold is applied.\n",
    "This algorithm can be useful `if the number of clusters is unknown`. By the threshold, we can control if we want to have many small and fine-grained cluster or few coarse-grained clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b951f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the embeddings to unit length\n",
    "corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform kmean clustering\n",
    "clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=1.5) #, affinity='cosine', linkage='average', distance_threshold=0.4)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sentences = {}\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_sentences:\n",
    "        clustered_sentences[cluster_id] = []\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cluster in clustered_sentences.items():\n",
    "    print(\"Cluster \", i)\n",
    "    print(cluster)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd00ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = len(clustered_sentences)\n",
    "vectors = corpus_embeddings\n",
    "_labels = clustering_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362c278",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algorithms = ['pca', 'tsne', 'umap'] \n",
    "dimentions = [ 2, 3 ]\n",
    "\n",
    "for red_algorithm in algorithms:\n",
    "    for plot_dim in dimentions:\n",
    "        plot(red_algorithm, plot_dim, num_clusters, vectors, _labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364b626",
   "metadata": {},
   "source": [
    "# Fast-Clustering\n",
    "---\n",
    "This is a more complex example on performing `clustering on large scale dataset`.\n",
    "This examples find in a large set of sentences local communities, i.e., `groups of sentences that are highly similar`. \n",
    "You can freely configure the threshold what is considered as similar. \n",
    "A `high threshold` will only find `extremely similar sentences`, a `lower threshold` will find more sentence that are `less similar`.\n",
    "A second parameter is `'min_community_size'`: Only communities with at least a certain number of sentences will be returned.\n",
    "The method for finding the communities is extremely fast, for clustering `50k sentences it requires only 5 seconds` (plus embedding comuptation).\n",
    "In this example, we download a large set of questions from Quora and then find similar questions in this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_detection(embeddings, threshold=0.75, min_community_size=10, init_max_size=1000):\n",
    "    \"\"\"\n",
    "    Function for Fast Community Detection\n",
    "    Finds in the embeddings all communities, i.e. embeddings that are close (closer than threshold).\n",
    "    Returns only communities that are larger than min_community_size. The communities are returned\n",
    "    in decreasing order. The first element in each list is the central point in the community.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute cosine similarity scores\n",
    "    cos_scores = util.pytorch_cos_sim(embeddings, embeddings)\n",
    "\n",
    "    # Minimum size for a community\n",
    "    top_k_values, _ = cos_scores.topk(k=min_community_size, largest=True)\n",
    "\n",
    "    # Filter for rows >= min_threshold\n",
    "    extracted_communities = []\n",
    "    for i in range(len(top_k_values)):\n",
    "        if top_k_values[i][-1] >= threshold:\n",
    "            new_cluster = []\n",
    "\n",
    "            # Only check top k most similar entries\n",
    "            top_val_large, top_idx_large = cos_scores[i].topk(k=init_max_size, largest=True)\n",
    "            top_idx_large = top_idx_large.tolist()\n",
    "            top_val_large = top_val_large.tolist()\n",
    "\n",
    "            if top_val_large[-1] < threshold:\n",
    "                for idx, val in zip(top_idx_large, top_val_large):\n",
    "                    if val < threshold:\n",
    "                        break\n",
    "\n",
    "                    new_cluster.append(idx)\n",
    "            else:\n",
    "                # Iterate over all entries (slow)\n",
    "                for idx, val in enumerate(cos_scores[i].tolist()):\n",
    "                    if val >= threshold:\n",
    "                        new_cluster.append(idx)\n",
    "\n",
    "            extracted_communities.append(new_cluster)\n",
    "\n",
    "    # Largest cluster first\n",
    "    extracted_communities = sorted(extracted_communities, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "    # Step 2) Remove overlapping communities\n",
    "    unique_communities = []\n",
    "    extracted_ids = set()\n",
    "\n",
    "    for community in extracted_communities:\n",
    "        add_cluster = True\n",
    "        for idx in community:\n",
    "            if idx in extracted_ids:\n",
    "                add_cluster = False\n",
    "                break\n",
    "\n",
    "        if add_cluster:\n",
    "            unique_communities.append(community)\n",
    "            for idx in community:\n",
    "                extracted_ids.add(idx)\n",
    "\n",
    "    return unique_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for computing sentence embeddings. We use one trained for similar questions detection\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-quora-ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00554c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We donwload the Quora Duplicate Questions Dataset (https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)\n",
    "# and find similar question in it\n",
    "max_corpus_size = 50000 # We limit our corpus to only the first 50k questions\n",
    "embedding_cache_path = '/home/vivoli/Thesis/data/clustering-samples/s2orc_corpus_sample-{}.pkl'.format(max_corpus_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if embedding cache path exists\n",
    "if not os.path.exists(embedding_cache_path):\n",
    "    # Check if the dataset exists. If not, download and extract\n",
    "    # Download dataset if needed\n",
    "\n",
    "    print(\"Encode the corpus. This might take a while\")\n",
    "    corpus_embeddings = model.encode(corpus, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "    print(\"Store file on disc\")\n",
    "    with open(embedding_cache_path, \"wb\") as fOut:\n",
    "        pickle.dump({'sentences': corpus, 'embeddings': corpus_embeddings}, fOut)\n",
    "else:\n",
    "    print(\"Load pre-computed embeddings from disc\")\n",
    "    with open(embedding_cache_path, \"rb\") as fIn:\n",
    "        cache_data = pickle.load(fIn)\n",
    "        corpus_sentences = cache_data['sentences']\n",
    "        corpus_embeddings = cache_data['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfce6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start clustering\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Two parameter to tune:\n",
    "# min_cluster_size: Only consider cluster that have at least 25 elements (30 similar sentences)\n",
    "# threshold: Consider sentence pairs with a cosine-similarity larger than threshold as similar\n",
    "clusters = community_detection(corpus_embeddings, min_community_size=25, threshold=0.2)\n",
    "\n",
    "print(\"Clustering done after {:.2f} sec\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "_len = 0\n",
    "for cluster in clusters:\n",
    "    _len += len(cluster)\n",
    "print(_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577bcfa9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Print all cluster / communities\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(\"\\nCluster {}, #{} Elements \".format(i+1, len(cluster)))\n",
    "    for sentence_id in cluster:\n",
    "        print(\"\\t\", corpus_sentences[sentence_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = len(clusters)\n",
    "vectors = corpus_embeddings[np.asarray(np.concatenate(clusters).flat)]\n",
    "_labels = np.asarray(np.concatenate([[idx]*len(cluster) for idx, cluster in enumerate(clusters)]).flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1d6c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algorithms = ['pca', 'tsne', 'umap'] \n",
    "dimentions = [ 2, 3 ]\n",
    "\n",
    "for red_algorithm in algorithms:\n",
    "    for plot_dim in dimentions:\n",
    "        plot(red_algorithm, plot_dim, num_clusters, vectors, _labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a129317",
   "metadata": {},
   "source": [
    "# UMAP\n",
    "---\n",
    "---\n",
    "Incredible: it works !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install numpy scipy -y; conda install scikit-learn -y; conda install numba -y; pip install umap-learn\n",
    "# !cd utils; wget https://github.com/lmcinnes/umap/archive/master.zip; unzip master.zip; rm master.zip; cd umap-master; conda install scikit-learn numba -y; python setup.py install\n",
    "# !pip install scipy\n",
    "# !cd utils; cd umap-master; pip install --user -r requirements.txt; python setup.py install --user\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import umap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = np.random.rand(800, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c643da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = umap.UMAP()\n",
    "%time u = fit.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7911369",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(u[:,0], u[:,1], c=data)\n",
    "plt.title('UMAP embedding of random colours');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_umap(n_neighbors=15, min_dist=0.1, n_components=2, metric='euclidean', title=''):\n",
    "    fit = umap.UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_components=n_components,\n",
    "        metric=metric\n",
    "    )\n",
    "    u = fit.fit_transform(data);\n",
    "    fig = plt.figure()\n",
    "    if n_components == 1:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], range(len(u)), c=data)\n",
    "    if n_components == 2:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], u[:,1], c=data)\n",
    "    if n_components == 3:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(u[:,0], u[:,1], u[:,2], c=data, s=100)\n",
    "    plt.title(title, fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f999c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n in (2, 5, 10, 20, 50, 100, 200):\n",
    "    draw_umap(n_neighbors=n, title='n_neighbors = {}'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in (0.0, 0.1, 0.25, 0.5, 0.8, 0.99):\n",
    "    draw_umap(min_dist=d, title='min_dist = {}'.format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa44a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_umap(n_components=1, title='n_components = 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_umap(n_components=3, title='n_components = 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a076585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f879d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "207ec6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def hue(r, g, b):\n",
    "    cmax = max(r, g, b)\n",
    "    cmin = min(r, g, b)\n",
    "    delta = cmax - cmin\n",
    "    if cmax == r:\n",
    "        return ((g - b) / delta) % 6\n",
    "    elif cmax == g:\n",
    "        return ((b - r) / delta) + 2\n",
    "    else:\n",
    "        return ((r - g) / delta) + 4\n",
    "\n",
    "@numba.njit()\n",
    "def lightness(r, g, b):\n",
    "    cmax = max(r, g, b)\n",
    "    cmin = min(r, g, b)\n",
    "    return (cmax + cmin) / 2.0\n",
    "\n",
    "@numba.njit()\n",
    "def saturation(r, g, b):\n",
    "    cmax = max(r, g, b)\n",
    "    cmin = min(r, g, b)\n",
    "    chroma = cmax - cmin\n",
    "    light = lightness(r, g, b)\n",
    "    if light == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return chroma / (1 - abs(2*light - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdbd8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def red_channel_dist(a,b):\n",
    "    return np.abs(a[0] - b[0])\n",
    "\n",
    "@numba.njit()\n",
    "def sl_dist(a, b):\n",
    "    a_sat = saturation(a[0], a[1], a[2])\n",
    "    b_sat = saturation(b[0], b[1], b[2])\n",
    "    a_light = lightness(a[0], a[1], a[2])\n",
    "    b_light = lightness(b[0], b[1], b[2])\n",
    "    return (a_sat - b_sat)**2 + (a_light - b_light)**2\n",
    "\n",
    "@numba.njit()\n",
    "def hue_dist(a, b):\n",
    "    diff = (hue(a[0], a[1], a[2]) - hue(b[0], b[1], b[2])) % 6\n",
    "    if diff < 0:\n",
    "        return diff + 6\n",
    "    else:\n",
    "        return diff\n",
    "\n",
    "@numba.njit()\n",
    "def hsl_dist(a, b):\n",
    "    a_sat = saturation(a[0], a[1], a[2])\n",
    "    b_sat = saturation(b[0], b[1], b[2])\n",
    "    a_light = lightness(a[0], a[1], a[2])\n",
    "    b_light = lightness(b[0], b[1], b[2])\n",
    "    a_hue = hue(a[0], a[1], a[2])\n",
    "    b_hue = hue(b[0], b[1], b[2])\n",
    "    return (a_sat - b_sat)**2 + (a_light - b_light)**2 + (((a_hue - b_hue) % 6) / 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "962ea447",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'draw_umap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d6fc80f822a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"euclidean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mred_channel_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhsl_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdraw_umap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'metric = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'draw_umap' is not defined"
     ]
    }
   ],
   "source": [
    "for m in (\"euclidean\", red_channel_dist, sl_dist, hue_dist, hsl_dist):\n",
    "    name = m if type(m) is str else m.__name__\n",
    "    draw_umap(n_components=2, metric=m, title='metric = {}'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b974ef1",
   "metadata": {},
   "source": [
    "# 3d interaction\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3503414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee3e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = np.random.random((3, 10000))\n",
    "ipv.quickscatter(x, y, z, size=1, marker=\"sphere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipyvolume as ipv\n",
    "V = np.zeros((128,128,128)) # our 3d array\n",
    "# outer box\n",
    "V[30:-30,30:-30,30:-30] = 0.75\n",
    "V[35:-35,35:-35,35:-35] = 0.0\n",
    "# inner box\n",
    "V[50:-50,50:-50,50:-50] = 0.25\n",
    "V[55:-55,55:-55,55:-55] = 0.0\n",
    "ipv.quickvolshow(V, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}